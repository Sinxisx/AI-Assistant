{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define Functions & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API_URL = \"http://localhost:11434/api/chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_setup():\n",
    "    instruction = 'You are a friendly and helpful data analyst. The user will ask you question about data analysis, be prepared.'\n",
    "    chat= [{'role':'system',\n",
    "            'content':instruction}]\n",
    "    payload = {\n",
    "    \"model\":\"deepseek-r1:8b\",\n",
    "    \"messages\":chat,\n",
    "    \"stream\":False,\n",
    "    \"temperature\": 0.0\n",
    "}\n",
    "    response = requests.post(OLLAMA_API_URL,json=payload).json()\n",
    "\n",
    "    chat.append({'role':'assistant',\n",
    "                        'content':response['message']['content']})\n",
    "    return chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_query(natural_language):\n",
    "    # Get the current directory of the script\n",
    "    script_dir = Path.cwd()\n",
    "\n",
    "    # Navigate to the parent directory and then into the Context folder\n",
    "    context_dir = script_dir.parent / \"Context\"\n",
    "\n",
    "    # Construct the full path to the file\n",
    "    file_path = context_dir / \"MASTER_FUNDING.txt\"\n",
    "\n",
    "    # Open context file in read mode\n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Read the entire file content\n",
    "        content = file.read()\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an expert SQL generator. Translate the following natural language request into a valid SQL query. \n",
    "Make sure the query is properly formatted and is tailored for our database schema.\n",
    "The table in the database is master_funding, it uses the following schema:\n",
    "{content}\n",
    "\n",
    "Request: {natural_language}\n",
    "\n",
    "SQL Query:\n",
    "\"\"\"\n",
    "    payload = {\n",
    "        \"model\": \"deepseek-r1:8b\",  # if needed, or remove if the API defaults to it\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.0,  # Lower temperature can help ensure deterministic output\n",
    "        \"stream\":False\n",
    "    }\n",
    "    response = requests.post(OLLAMA_API_URL, json=payload)\n",
    "    response_data = response.json()\n",
    "    \n",
    "    # The structure may vary based on the API; assume generated text is in this field:\n",
    "    sql_query = response_data.get(\"generated_text\", \"\").strip()\n",
    "    return sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_insight(natural_language, sql_query, query_result):\n",
    "    # Format the query result in a readable way (e.g., JSON)\n",
    "    formatted_result = json.dumps(query_result, indent=2)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are a data analyst. You first received the following natural language request:\n",
    "\"{natural_language}\"\n",
    "\n",
    "Based on that, an SQL query was generated and executed:\n",
    "{sql_query}\n",
    "\n",
    "The query returned the following result:\n",
    "{formatted_result}\n",
    "\n",
    "Please provide a detailed explanation of the insights, trends, or key points that can be derived from these results.\n",
    "\"\"\"\n",
    "    payload = {\n",
    "        \"model\": \"deepseek-r1:8b\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "    response = requests.post(OLLAMA_API_URL, json=payload)\n",
    "    response_data = response.json()\n",
    "    insight = response_data.get(\"generated_text\", \"\").strip()\n",
    "    return insight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_database(sql_query):\n",
    "    API_URL = \"http://127.0.0.1:8000/query\"\n",
    "    response = requests.post(API_URL, json={\"query\": sql_query})\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_hist = initial_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a friendly and helpful data analyst. The user will ask you question about data analysis, be prepared.'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"<think>\\nOkay, so the user wants to understand how to approach data analysis in their project. Let me break down what they might need.\\n\\nFirst, I should figure out the main goal of their project. Is it descriptive analytics, which means summarizing data, or something more advanced like predictive analytics? Knowing this will help determine the tools and techniques to use.\\n\\nNext, they'll probably need a clear dataset. What variables are involved? Are there any missing values or outliers that could affect the analysis? Cleaning the data might be necessary at this stage.\\n\\nThey might also require transforming the data to make it more usable. Maybe they need to create new features or handle time series data. I should consider what kind of transformations would add value.\\n\\nChoosing the right tools is important too. Depending on their skill level and project complexity, they might use Excel for simple tasks or move to Python with libraries like Pandas or TensorFlow for more complex models.\\n\\nVisualization is another key aspect. They'll need to present their findings clearly. I should suggest which graphs or charts would best convey their insights, like bar charts for distributions or line graphs for trends.\\n\\nInterpretation is where they connect the analysis back to the business context. I should help them frame their results in a way that's understandable and actionable for stakeholders.\\n\\nFinally, checking assumptions and validity ensures their conclusions are reliable. They'll need to verify if their data meets the necessary conditions for their analysis methods.\\n\\nOverall, guiding them through these steps will give them a solid framework for their project.\\n</think>\\n\\nCertainly! Let's break it down step by step:\\n\\n1. **Define the Goal**: What are you trying to achieve with your data? Are you looking for trends, forecasting future values, analyzing customer behavior, or something else?\\n\\n2. **Understand Your Data**: Who is your audience? What variables are you analyzing (e.g., demographics, sales, social media metrics, etc.)? Are there any missing data points or outliers that need attention?\\n\\n3. **Clean and Prepare the Data**:\\n   - Remove duplicates.\\n   - Handle missing values appropriately.\\n   - Check for anomalies or outliers.\\n   - Normalize the data if necessary.\\n\\n4. **Choose Your Tools**: Depending on your skill level and the complexity of your project, you can use Excel, Google Sheets, R, Python (with libraries like Pandas, Matplotlib, Seaborn), Tableau, Power BI, etc.\\n\\n5. **Analyze the Data**:\\n   - Use descriptive statistics to summarize your data.\\n   - Look for patterns or relationships between variables using correlation and regression analysis if needed.\\n   - Segment your data to analyze specific subsets (e.g., by gender, location, or time period).\\n\\n6. **Visualize Your Findings**: Create charts, graphs, or dashboards to make your analysis more understandable.\\n\\n7. **Interpret the Results**: Connect your findings back to your original goal. What story can you tell with your data? Are there actionable insights?\\n\\n8. **Validate and Refine**: Double-check your analysis for accuracy. If necessary, iterate on your methods or re-examine your assumptions based on the results.\\n\\n9. **Document Your Process**: Keep a record of your steps, tools used, and any decisions made during the analysis process.\\n\\n10. **Present Your Work**: Share your findings clearly and concisely, whether it's in a report, presentation, or dashboard.\\n\\nNeed help with something specific? Let me know!\"}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_language = \"What month has the highest amount of funding?\"\n",
    "\n",
    "# Get the current directory of the script\n",
    "script_dir = Path.cwd()\n",
    "\n",
    "# Navigate to the parent directory and then into the Context folder\n",
    "context_dir = script_dir.parent / \"Context\"\n",
    "\n",
    "# Construct the full path to the file\n",
    "file_path = context_dir / \"MASTER_FUNDING.txt\"\n",
    "\n",
    "# Open context file in read mode\n",
    "with open(file_path, \"r\") as file:\n",
    "    # Read the entire file content\n",
    "    content = file.read()\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an expert SQL generator. Translate the following natural language request into a valid SQL query. \n",
    "Make sure the query is properly formatted and is tailored for our database schema.\n",
    "The table in the database is master_funding, it uses the following schema:\n",
    "{content}\n",
    "\n",
    "Request: {natural_language}\n",
    "\n",
    "SQL Query:\n",
    "\"\"\"\n",
    "\n",
    "chat_hist.append({\"role\":\"user\",\"content\":prompt})\n",
    "payload = {\n",
    "    \"model\": \"deepseek-r1:8b\",  # if needed, or remove if the API defaults to it\n",
    "    \"messages\": chat_hist,\n",
    "    \"temperature\": 0.0,  # Lower temperature can help ensure deterministic output\n",
    "    \"stream\":False\n",
    "}\n",
    "response = requests.post(OLLAMA_API_URL, json=payload).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = response['message']['content']\n",
    "chat_hist.append({'role':'assistant',\n",
    "                  'content':reply})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, so I need to figure out which month has the highest amount of funding. The data is stored in a table called master_funding, and I have access to various fields related to each account\\'s funding details.\\n\\nFirst, I should identify the relevant columns for this query. The user is asking about the month with the highest funding, so I need a column that represents the month, like BASE_YM, which is set as YYYYMM. That seems perfect because it captures the year and month in a four-digit format.\\n\\nNext, I need to find out the amount of funding for each month. The field BASE_AMT_FIX appears to hold the end-of-day funding amount, so that\\'s the measure we want to maximize.\\n\\nI should group the data by BASE_YM to aggregate the funding amounts per month. Using the GROUP BY clause in SQL would help with this.\\n\\nOnce grouped, I can calculate the maximum value for each month using MAX(BASE_AMT_FIX). This will give me the highest funding amount for each specific month across all accounts.\\n\\nTo get the month name instead of the numerical YYYYMM format, I might need another table or a function that converts BASE_YM into an actual month name. For simplicity, assuming there\\'s no additional lookup table provided, I\\'ll work with the numerical value in this query.\\n\\nFinally, ordering the results by MAX(BASE_AMT_FIX) DESC will show me which months have the highest funding amounts in descending order.\\n\\nPutting it all together, my SQL query should select the distinct months, group them by BASE_YM, find the maximum funding amount for each month, and then order those amounts from highest to lowest.\\n</think>\\n\\nTo determine which month has the highest amount of funding, you can use an SQL query that aggregates the funding data by month and identifies the maximum value. Here\\'s how you can do it:\\n\\n**SQL Query:**\\n\\n```sql\\nSELECT DISTINCT \\n    BASE_YM AS \"Month\",\\n    MAX(BASE_AMT_FIX) AS \"Highest Funding Amount\"\\nFROM master_funding\\nGROUP BY BASE_YM\\nORDER BY \"Highest Funding Amount\" DESC;\\n```\\n\\n**Explanation:**\\n\\n1. **`SELECT DISTINCT`:** This ensures that only unique months are considered, avoiding redundant data.\\n\\n2. **`BASE_YM`:** This column represents the month in a four-digit format (e.g., 202303 for March 2023). It is used to group the data by month.\\n\\n3. **`MAX(BASE_AMT_FIX)`:** This calculates the maximum funding amount for each specific month. `BASE_AMT_fix` likely holds the end-of-day funding amount, making it suitable for this measurement.\\n\\n4. **`GROUP BY BASE_YM`:** This groups rows that share the same month value together.\\n\\n5. **`ORDER BY \"Highest Funding Amount\" DESC`:** This sorts the results by the highest funding amount in descending order, allowing you to see which month has the highest funding.\\n\\nThis query will return a list of months along with their corresponding maximum funding amounts, giving you clear insight into which month had the highest funding.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SQL query\n",
    "pattern = r\"```sql\\n(.*?)\\n```\"\n",
    "\n",
    "# Search for the pattern\n",
    "match = re.search(pattern, reply, re.DOTALL)\n",
    "\n",
    "# Extracted SQL query\n",
    "sql_query = match.group(1) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT DISTINCT \n",
      "    BASE_YM AS \"Month\",\n",
      "    MAX(BASE_AMT_FIX) AS \"Highest Funding Amount\"\n",
      "FROM master_funding\n",
      "GROUP BY BASE_YM\n",
      "ORDER BY \"Highest Funding Amount\" DESC;\n"
     ]
    }
   ],
   "source": [
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'month': 202501, 'highest funding amount': 535000000000.0},\n",
       "  {'month': 202411, 'highest funding amount': 153809364652.52},\n",
       "  {'month': 202412, 'highest funding amount': 150000000000.0},\n",
       "  {'month': 202405, 'highest funding amount': 140610631177.91},\n",
       "  {'month': 202407, 'highest funding amount': 102000407000.0},\n",
       "  {'month': 202403, 'highest funding amount': 100000000000.0},\n",
       "  {'month': 202408, 'highest funding amount': 82684250000.0},\n",
       "  {'month': 202404, 'highest funding amount': 65115312742.8},\n",
       "  {'month': 202410, 'highest funding amount': 65000000000.0},\n",
       "  {'month': 202406, 'highest funding amount': 56000000000.0},\n",
       "  {'month': 202212, 'highest funding amount': 50361419319.0},\n",
       "  {'month': 202310, 'highest funding amount': 50000000000.0},\n",
       "  {'month': 202401, 'highest funding amount': 50000000000.0},\n",
       "  {'month': 202308, 'highest funding amount': 46609845490.1764},\n",
       "  {'month': 202309, 'highest funding amount': 34260353348.16},\n",
       "  {'month': 202409, 'highest funding amount': 27000000000.0},\n",
       "  {'month': 202402, 'highest funding amount': 23582326160.21}]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try using the api\n",
    "query_database(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing SQL query: SELECT DISTINCT \n",
      "    BASE_YM AS \"Month\",\n",
      "    MAX(BASE_AMT_FIX) AS \"Highest Funding Amount\"\n",
      "FROM master_funding\n",
      "GROUP BY BASE_YM\n",
      "ORDER BY \"Highest Funding Amount\" DESC;\n",
      "Query Result: {'data': [{'month': 202501, 'highest funding amount': 535000000000.0}, {'month': 202411, 'highest funding amount': 153809364652.52}, {'month': 202412, 'highest funding amount': 150000000000.0}, {'month': 202405, 'highest funding amount': 140610631177.91}, {'month': 202407, 'highest funding amount': 102000407000.0}, {'month': 202403, 'highest funding amount': 100000000000.0}, {'month': 202408, 'highest funding amount': 82684250000.0}, {'month': 202404, 'highest funding amount': 65115312742.8}, {'month': 202410, 'highest funding amount': 65000000000.0}, {'month': 202406, 'highest funding amount': 56000000000.0}, {'month': 202212, 'highest funding amount': 50361419319.0}, {'month': 202310, 'highest funding amount': 50000000000.0}, {'month': 202401, 'highest funding amount': 50000000000.0}, {'month': 202308, 'highest funding amount': 46609845490.1764}, {'month': 202309, 'highest funding amount': 34260353348.16}, {'month': 202409, 'highest funding amount': 27000000000.0}, {'month': 202402, 'highest funding amount': 23582326160.21}]}\n"
     ]
    }
   ],
   "source": [
    "if sql_query:\n",
    "    print(\"Executing SQL query\")\n",
    "    result = query_database(sql_query)\n",
    "    print(\"Query Result:\", result)\n",
    "else:\n",
    "    print(\"No SQL query found in response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_result = json.dumps(result, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate insight\n",
    "prompt = f\"\"\"\n",
    "You are a data analyst. You first received the following natural language request:\n",
    "\"{natural_language}\"\n",
    "\n",
    "Based on that, an SQL query was generated and executed:\n",
    "{sql_query}\n",
    "\n",
    "The query returned the following result:\n",
    "{formatted_result}\n",
    "\n",
    "Please provide a detailed explanation of the insights, trends, or key points that can be derived from these results.\n",
    "\"\"\"\n",
    "chat_hist.append({\"role\":\"user\",\"content\":prompt})\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"deepseek-r1:8b\",\n",
    "    \"messages\": chat_hist,\n",
    "    \"temperature\": 0.7,\n",
    "    \"stream\":False\n",
    "}\n",
    "response = requests.post(OLLAMA_API_URL, json=payload).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n**Insights and Key Points Derived from the Results**\\n\\n1. **Month with the Highest Funding:**\\n   - **January 2025 (202501)** holds the title of having the highest funding amount of **$535,000,000,000.00**, significantly higher than any other month.\\n\\n2. **Trend Observations:**\\n   - **Seasonal Variation:** The data shows a noticeable decrease in funding amounts as we move away from January 2025 towards later months, indicating a peak in funding during the beginning of the year.\\n   \\n3. **Key Funding Peaks:**\\n   - Besides January, other months like November (202411) and December (202412) also have notably high funding amounts, suggesting that significant investments occur towards the end of the year.\\n\\n4. **Consistency in Mid-Year Months:**\\n   - Months around mid-year, such as July (202407), August (202408), and September (202409), consistently receive substantial funding, but they are overshadowed by January's peak.\\n\\n5. **Year-on-Year Comparison:**\\n   - Comparing across different years would provide a comprehensive view of funding trends over time. This analysis is not included in the current dataset, but it could offer deeper insights into long-term patterns.\\n\\n6. **Data Quality Considerations:**\\n   - The data seems to accurately reflect funding trends, but further validation against external sources or additional metadata might be necessary to ensure its integrity.\\n\\n**Conclusion:**\\n\\nThe data highlights that January 2025 has the highest funding amount, with other months showing varying levels of investment. This peak in January suggests a significant annual event or period when these funds are allocated. Tracking this over multiple years could provide valuable insights into organizational financing patterns and resource allocation strategies.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection info\n",
    "host= 'localhost'\n",
    "port= '5432'\n",
    "database= 'postgres'\n",
    "username= 'postgres'\n",
    "password= os.environ['PGPW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    print(\"Hello world\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
